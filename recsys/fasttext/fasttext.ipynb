{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df = pd.read_csv('final_book3.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('emb_value.csv')\n",
    "\n",
    "import ast\n",
    "# 문자열을 리스트로 변환\n",
    "df['embedding_책소개'] = df['embedding_책소개'].apply(lambda x: list(map(float, x.replace('\\n', '')[1:-1].split())))\n",
    "\n",
    "from gensim.models import FastText"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "ename": "UnpicklingError",
     "evalue": "could not find MARK",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "File \u001b[1;32mc:\\Users\\mysorol\\anaconda3\\envs\\nlp\\lib\\site-packages\\gensim\\models\\fasttext.py:932\u001b[0m, in \u001b[0;36mFastText.load\u001b[1;34m(cls, *args, **kwargs)\u001b[0m\n\u001b[0;32m    931\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 932\u001b[0m     model \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mFastText\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mcls\u001b[39;49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    934\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(model\u001b[38;5;241m.\u001b[39mtrainables, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mvectors_vocab_lockf\u001b[39m\u001b[38;5;124m'\u001b[39m) \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(model\u001b[38;5;241m.\u001b[39mwv, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mvectors_vocab\u001b[39m\u001b[38;5;124m'\u001b[39m):\n",
      "File \u001b[1;32mc:\\Users\\mysorol\\anaconda3\\envs\\nlp\\lib\\site-packages\\gensim\\models\\base_any2vec.py:1230\u001b[0m, in \u001b[0;36mBaseWordEmbeddingsModel.load\u001b[1;34m(cls, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1201\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Load a previously saved object (using :meth:`~gensim.models.base_any2vec.BaseWordEmbeddingsModel.save`) from file.\u001b[39;00m\n\u001b[0;32m   1202\u001b[0m \n\u001b[0;32m   1203\u001b[0m \u001b[38;5;124;03mAlso initializes extra instance attributes in case the loaded model does not include them.\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1228\u001b[0m \n\u001b[0;32m   1229\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m-> 1230\u001b[0m model \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mBaseWordEmbeddingsModel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mcls\u001b[39;49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1231\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(model, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mns_exponent\u001b[39m\u001b[38;5;124m'\u001b[39m):\n",
      "File \u001b[1;32mc:\\Users\\mysorol\\anaconda3\\envs\\nlp\\lib\\site-packages\\gensim\\models\\base_any2vec.py:602\u001b[0m, in \u001b[0;36mBaseAny2VecModel.load\u001b[1;34m(cls, fname_or_handle, **kwargs)\u001b[0m\n\u001b[0;32m    577\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Load a previously saved object (using :meth:`gensim.models.base_any2vec.BaseAny2VecModel.save`) from a file.\u001b[39;00m\n\u001b[0;32m    578\u001b[0m \n\u001b[0;32m    579\u001b[0m \u001b[38;5;124;03mParameters\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    600\u001b[0m \n\u001b[0;32m    601\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m--> 602\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mBaseAny2VecModel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mcls\u001b[39;49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfname_or_handle\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\mysorol\\anaconda3\\envs\\nlp\\lib\\site-packages\\gensim\\utils.py:436\u001b[0m, in \u001b[0;36mSaveLoad.load\u001b[1;34m(cls, fname, mmap)\u001b[0m\n\u001b[0;32m    435\u001b[0m obj \u001b[38;5;241m=\u001b[39m unpickle(fname)\n\u001b[1;32m--> 436\u001b[0m \u001b[43mobj\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_load_specials\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfname\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmmap\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcompress\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msubname\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    437\u001b[0m logger\u001b[38;5;241m.\u001b[39minfo(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mloaded \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m\"\u001b[39m, fname)\n",
      "File \u001b[1;32mc:\\Users\\mysorol\\anaconda3\\envs\\nlp\\lib\\site-packages\\gensim\\utils.py:505\u001b[0m, in \u001b[0;36mSaveLoad._load_specials\u001b[1;34m(self, fname, mmap, compress, subname)\u001b[0m\n\u001b[0;32m    504\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m ignore_deprecation_warning():\n\u001b[1;32m--> 505\u001b[0m     \u001b[38;5;28;43msetattr\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mattrib\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\mysorol\\anaconda3\\envs\\nlp\\lib\\site-packages\\gensim\\utils.py:1461\u001b[0m, in \u001b[0;36mdeprecated.<locals>.decorator.<locals>.new_func1\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m   1456\u001b[0m warnings\u001b[38;5;241m.\u001b[39mwarn(\n\u001b[0;32m   1457\u001b[0m     fmt\u001b[38;5;241m.\u001b[39mformat(name\u001b[38;5;241m=\u001b[39mfunc\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m, reason\u001b[38;5;241m=\u001b[39mreason),\n\u001b[0;32m   1458\u001b[0m     category\u001b[38;5;241m=\u001b[39m\u001b[38;5;167;01mDeprecationWarning\u001b[39;00m,\n\u001b[0;32m   1459\u001b[0m     stacklevel\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m2\u001b[39m\n\u001b[0;32m   1460\u001b[0m )\n\u001b[1;32m-> 1461\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\mysorol\\anaconda3\\envs\\nlp\\lib\\site-packages\\gensim\\models\\base_any2vec.py:861\u001b[0m, in \u001b[0;36mBaseWordEmbeddingsModel.cum_table\u001b[1;34m(self, value)\u001b[0m\n\u001b[0;32m    858\u001b[0m \u001b[38;5;129m@cum_table\u001b[39m\u001b[38;5;241m.\u001b[39msetter\n\u001b[0;32m    859\u001b[0m \u001b[38;5;129m@deprecated\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mAttribute will be removed in 4.0.0, use self.vocabulary.cum_table instead\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    860\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcum_table\u001b[39m(\u001b[38;5;28mself\u001b[39m, value):\n\u001b[1;32m--> 861\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mvocabulary\u001b[49m\u001b[38;5;241m.\u001b[39mcum_table \u001b[38;5;241m=\u001b[39m value\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'FastText' object has no attribute 'vocabulary'",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mUnpicklingError\u001b[0m                           Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[7], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# FastText 모델 불러오기\u001b[39;00m\n\u001b[1;32m----> 2\u001b[0m fasttext_model \u001b[38;5;241m=\u001b[39m \u001b[43mFastText\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43mr\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mC:\u001b[39;49m\u001b[38;5;124;43m\\\u001b[39;49m\u001b[38;5;124;43mUsers\u001b[39;49m\u001b[38;5;124;43m\\\u001b[39;49m\u001b[38;5;124;43mmysorol\u001b[39;49m\u001b[38;5;124;43m\\\u001b[39;49m\u001b[38;5;124;43m바탕 화면\u001b[39;49m\u001b[38;5;124;43m\\\u001b[39;49m\u001b[38;5;124;43mimworking\u001b[39;49m\u001b[38;5;124;43m\\\u001b[39;49m\u001b[38;5;124;43mchkchk\u001b[39;49m\u001b[38;5;124;43m\\\u001b[39;49m\u001b[38;5;124;43mcontents_based\u001b[39;49m\u001b[38;5;124;43m\\\u001b[39;49m\u001b[38;5;124;43mfasttext_model.bin\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\mysorol\\anaconda3\\envs\\nlp\\lib\\site-packages\\gensim\\models\\fasttext.py:944\u001b[0m, in \u001b[0;36mFastText.load\u001b[1;34m(cls, *args, **kwargs)\u001b[0m\n\u001b[0;32m    942\u001b[0m     logger\u001b[38;5;241m.\u001b[39minfo(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mModel saved using code from earlier Gensim Version. Re-loading old model in a compatible way.\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m    943\u001b[0m     \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mgensim\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmodels\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdeprecated\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mfasttext\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m load_old_fasttext\n\u001b[1;32m--> 944\u001b[0m     model \u001b[38;5;241m=\u001b[39m \u001b[43mload_old_fasttext\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    946\u001b[0m gensim\u001b[38;5;241m.\u001b[39mmodels\u001b[38;5;241m.\u001b[39mkeyedvectors\u001b[38;5;241m.\u001b[39m_try_upgrade(model\u001b[38;5;241m.\u001b[39mwv)\n\u001b[0;32m    948\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m model\n",
      "File \u001b[1;32mc:\\Users\\mysorol\\anaconda3\\envs\\nlp\\lib\\site-packages\\gensim\\models\\deprecated\\fasttext.py:52\u001b[0m, in \u001b[0;36mload_old_fasttext\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     51\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mload_old_fasttext\u001b[39m(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m---> 52\u001b[0m     old_model \u001b[38;5;241m=\u001b[39m \u001b[43mFastText\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     53\u001b[0m     params \u001b[38;5;241m=\u001b[39m {\n\u001b[0;32m     54\u001b[0m         \u001b[38;5;124m'\u001b[39m\u001b[38;5;124msize\u001b[39m\u001b[38;5;124m'\u001b[39m: old_model\u001b[38;5;241m.\u001b[39mvector_size,\n\u001b[0;32m     55\u001b[0m         \u001b[38;5;124m'\u001b[39m\u001b[38;5;124malpha\u001b[39m\u001b[38;5;124m'\u001b[39m: old_model\u001b[38;5;241m.\u001b[39malpha,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     75\u001b[0m         \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mbucket\u001b[39m\u001b[38;5;124m'\u001b[39m: old_model\u001b[38;5;241m.\u001b[39mbucket\n\u001b[0;32m     76\u001b[0m     }\n\u001b[0;32m     77\u001b[0m     new_model \u001b[38;5;241m=\u001b[39m NewFastText(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mparams)\n",
      "File \u001b[1;32mc:\\Users\\mysorol\\anaconda3\\envs\\nlp\\lib\\site-packages\\gensim\\models\\deprecated\\word2vec.py:1617\u001b[0m, in \u001b[0;36mWord2Vec.load\u001b[1;34m(cls, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1615\u001b[0m \u001b[38;5;129m@classmethod\u001b[39m\n\u001b[0;32m   1616\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mload\u001b[39m(\u001b[38;5;28mcls\u001b[39m, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m-> 1617\u001b[0m     model \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mWord2Vec\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mcls\u001b[39;49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1618\u001b[0m     \u001b[38;5;66;03m# update older models\u001b[39;00m\n\u001b[0;32m   1619\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(model, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtable\u001b[39m\u001b[38;5;124m'\u001b[39m):\n",
      "File \u001b[1;32mc:\\Users\\mysorol\\anaconda3\\envs\\nlp\\lib\\site-packages\\gensim\\models\\deprecated\\old_saveload.py:87\u001b[0m, in \u001b[0;36mSaveLoad.load\u001b[1;34m(cls, fname, mmap)\u001b[0m\n\u001b[0;32m     83\u001b[0m logger\u001b[38;5;241m.\u001b[39minfo(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mloading \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m object from \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28mcls\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m, fname)\n\u001b[0;32m     85\u001b[0m compress, subname \u001b[38;5;241m=\u001b[39m SaveLoad\u001b[38;5;241m.\u001b[39m_adapt_by_suffix(fname)\n\u001b[1;32m---> 87\u001b[0m obj \u001b[38;5;241m=\u001b[39m \u001b[43munpickle\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfname\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     88\u001b[0m obj\u001b[38;5;241m.\u001b[39m_load_specials(fname, mmap, compress, subname)\n\u001b[0;32m     89\u001b[0m logger\u001b[38;5;241m.\u001b[39minfo(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mloaded \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m\"\u001b[39m, fname)\n",
      "File \u001b[1;32mc:\\Users\\mysorol\\anaconda3\\envs\\nlp\\lib\\site-packages\\gensim\\models\\deprecated\\old_saveload.py:379\u001b[0m, in \u001b[0;36munpickle\u001b[1;34m(fname)\u001b[0m\n\u001b[0;32m    376\u001b[0m file_bytes \u001b[38;5;241m=\u001b[39m file_bytes\u001b[38;5;241m.\u001b[39mreplace(\n\u001b[0;32m    377\u001b[0m     \u001b[38;5;124mb\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mgensim.models.wrappers.fasttext\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124mb\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mgensim.models.deprecated.fasttext_wrapper\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m    378\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m sys\u001b[38;5;241m.\u001b[39mversion_info \u001b[38;5;241m>\u001b[39m (\u001b[38;5;241m3\u001b[39m, \u001b[38;5;241m0\u001b[39m):\n\u001b[1;32m--> 379\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_pickle\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mloads\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfile_bytes\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mencoding\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mlatin1\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m    380\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    381\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m _pickle\u001b[38;5;241m.\u001b[39mloads(file_bytes)\n",
      "\u001b[1;31mUnpicklingError\u001b[0m: could not find MARK"
     ]
    }
   ],
   "source": [
    "# FastText 모델 불러오기\n",
    "fasttext_model = FastText.load(r'C:\\Users\\mysorol\\바탕 화면\\imworking\\chkchk\\contents_based\\fasttext_model.bin')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\nunic\\AppData\\Local\\Temp\\ipykernel_19416\\857311142.py:41: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  recommended_books['cos'] = recommended_books.index.map(lambda x: similarity_scores[x])\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "# 사용자 입력받기\n",
    "user_books = ['바보멍청이똥개','트렌드 코리아 2025', '회계 천재가 된 홍대리', '모두의 금리', '돈 공부를 시작하고 인생의 불안이 사라졌다', '도쿄 트렌드 인사이트 2025', '레버리지', '부의 시나리오', '로지컬 씽킹', '피터 드러커 자기경영노트', '60년대생이 온다','자본주의']\n",
    "M = 10  # 추천할 책 개수인사\n",
    "\n",
    "# 1. DB에서 일치하는 책 찾기 (제목 컬럼 사용)\n",
    "matched_books = df[df['title'].isin(user_books)]\n",
    "\n",
    "if matched_books.shape[0] == 0:\n",
    "    print(\"일치하는 책이 없습니다.\")\n",
    "else:\n",
    "    # 2. 입력한 책들의 책소개 임베딩 가져오기\n",
    "    matched_embeddings = np.array([\n",
    "        df['embedding_책소개'].iloc[i]\n",
    "        for i in matched_books.index\n",
    "    ])\n",
    "\n",
    "    # 3. 모든 책의 책소개 임베딩 결합\n",
    "    all_embeddings = np.array([\n",
    "        df['embedding_책소개'].iloc[i]\n",
    "        for i in range(len(df))\n",
    "    ])\n",
    "\n",
    "    # 4. 사용자 책 임베딩 평균\n",
    "    user_embedding = np.mean(matched_embeddings, axis=0).reshape(1, -1)\n",
    "\n",
    "    # 5. 코사인 유사도 계산\n",
    "    similarity_scores = cosine_similarity(user_embedding, all_embeddings).flatten()\n",
    "\n",
    "    # 6. 가장 유사한 M권의 책 추천 (단, 입력한 책과 일치하는 책은 제외)\n",
    "    recommended_books_indices = np.argsort(similarity_scores)[-M-1:-1]  # 가장 유사한 M권 인덱스\n",
    "    # recommended_books_indices = np.argpartition(similarity_scores, -M-1)[-M-1:]\n",
    "    recommended_books_indices = [idx for idx in recommended_books_indices if idx not in matched_books.index]  # 제외\n",
    "\n",
    "\n",
    "    # 7. 추천 책 가져오기\n",
    "    recommended_books = df.iloc[recommended_books_indices]\n",
    "    recommended_books['cos'] = recommended_books.index.map(lambda x: similarity_scores[x])\n",
    "    recommended_books[['title', 'full_name', 'cos']].sort_values(by='cos', ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>full_name</th>\n",
       "      <th>cos</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>24094</th>\n",
       "      <td>2015 현대경제연구원 휴가철 선정도서 세트</td>\n",
       "      <td>2015 현대경제연구원 휴가철 선정도서 세트   [ 전11권 ]</td>\n",
       "      <td>0.923334</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11688</th>\n",
       "      <td>골든 크로스</td>\n",
       "      <td>골든 크로스 주식과 부동산의 위기를 기회로 만드는 투자 전략</td>\n",
       "      <td>0.920871</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5830</th>\n",
       "      <td>100대 기업 ESG 담당자가 가장 자주 하는 질문</td>\n",
       "      <td>100대 기업 ESG 담당자가 가장 자주 하는 질문</td>\n",
       "      <td>0.918648</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17110</th>\n",
       "      <td>그린란드상어처럼 생존하라</td>\n",
       "      <td>그린란드상어처럼 생존하라 부분에선 실패해도 전체에선 이기는 기업의 생존기술</td>\n",
       "      <td>0.916318</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51856</th>\n",
       "      <td>내 인생의 후반전은 아직 결정되지 않았다</td>\n",
       "      <td>내 인생의 후반전은 아직 결정되지 않았다</td>\n",
       "      <td>0.916292</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12531</th>\n",
       "      <td>부의 재편</td>\n",
       "      <td>부의 재편 새로운 부와 마켓, 그리고 전혀 다른 기회</td>\n",
       "      <td>0.916143</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4604</th>\n",
       "      <td>장하준의 경제학 명강의 시리즈 세트</td>\n",
       "      <td>장하준의 경제학 명강의 시리즈 세트 나쁜 사마리아인들 + 그들이 말하지 않는 23가...</td>\n",
       "      <td>0.916015</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37463</th>\n",
       "      <td>후즈유어시티 WHO'S YOUR CITY</td>\n",
       "      <td>후즈유어시티 WHO'S YOUR CITY 세계의 경제 엘리트들은 어디서 사는가</td>\n",
       "      <td>0.915794</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20948</th>\n",
       "      <td>퍼스트 무버 4차 산업혁명의 선도자들</td>\n",
       "      <td>퍼스트 무버 4차 산업혁명의 선도자들</td>\n",
       "      <td>0.915412</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1258</th>\n",
       "      <td>피크아웃 코리아</td>\n",
       "      <td>피크아웃 코리아 미래가 없는 사회에서 살아남기</td>\n",
       "      <td>0.915330</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                              title  \\\n",
       "24094      2015 현대경제연구원 휴가철 선정도서 세트   \n",
       "11688                        골든 크로스   \n",
       "5830   100대 기업 ESG 담당자가 가장 자주 하는 질문   \n",
       "17110                 그린란드상어처럼 생존하라   \n",
       "51856        내 인생의 후반전은 아직 결정되지 않았다   \n",
       "12531                         부의 재편   \n",
       "4604            장하준의 경제학 명강의 시리즈 세트   \n",
       "37463        후즈유어시티 WHO'S YOUR CITY   \n",
       "20948          퍼스트 무버 4차 산업혁명의 선도자들   \n",
       "1258                       피크아웃 코리아   \n",
       "\n",
       "                                               full_name       cos  \n",
       "24094                2015 현대경제연구원 휴가철 선정도서 세트   [ 전11권 ]  0.923334  \n",
       "11688                  골든 크로스 주식과 부동산의 위기를 기회로 만드는 투자 전략  0.920871  \n",
       "5830                        100대 기업 ESG 담당자가 가장 자주 하는 질문  0.918648  \n",
       "17110          그린란드상어처럼 생존하라 부분에선 실패해도 전체에선 이기는 기업의 생존기술  0.916318  \n",
       "51856                             내 인생의 후반전은 아직 결정되지 않았다  0.916292  \n",
       "12531                      부의 재편 새로운 부와 마켓, 그리고 전혀 다른 기회  0.916143  \n",
       "4604   장하준의 경제학 명강의 시리즈 세트 나쁜 사마리아인들 + 그들이 말하지 않는 23가...  0.916015  \n",
       "37463        후즈유어시티 WHO'S YOUR CITY 세계의 경제 엘리트들은 어디서 사는가  0.915794  \n",
       "20948                               퍼스트 무버 4차 산업혁명의 선도자들  0.915412  \n",
       "1258                           피크아웃 코리아 미래가 없는 사회에서 살아남기  0.915330  "
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "recommended_books[['title', 'full_name','cos']].sort_values(by='cos', ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'[ 0.04092156  1.1133122   0.09052531 -0.39455134  0.04127113 -0.266976\\n -0.3475721   0.17435507 -0.3709432  -0.71702355 -0.3044962   0.4867803\\n  0.01164729 -0.10703948 -0.80601984  0.8737641  -0.3737457   0.50404596\\n  0.16038355  0.7477061  -0.3160667  -0.9024943  -0.70185596  0.7842009\\n -0.04970044 -0.09249415  0.15315756  0.5105449   0.18726115 -0.3059648\\n  0.00770184 -0.6144606  -1.1997863  -0.37914553 -1.2983112   0.26560637\\n  0.9054487   0.30595112 -0.1032512  -0.21743514  0.020437   -0.15651014\\n -0.14259472 -0.7517462   0.02914969 -0.39765593  0.34780216 -0.34752834\\n -0.9567127   0.19733387 -1.0115819  -0.31952977 -0.12017702 -0.0381263\\n  0.08930171 -0.3932289  -0.37033647  0.49290457 -0.12076207 -0.17082429\\n  0.39826146 -1.3247088  -0.42003566  0.36601558  0.0137801  -0.31784308\\n -0.00620803 -0.5367416  -0.29305542  0.02867975  0.07108983  0.5972097\\n  0.29905984  0.00325138  0.4339783   0.5860185   0.34903544 -0.3006662\\n -0.16366321  0.18403576 -1.2186208  -0.4897524   0.55092233 -0.01485768\\n  0.57503587  0.6124053   0.472038    0.06387361  0.20928416  0.5541025\\n  0.8458271   0.02851025  0.4437632  -0.6861317  -0.09523315  0.34484944\\n  0.6553145  -0.75045663  0.22410694 -0.01154346]'"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = df['embedding_책소개'][3]\n",
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'list' object has no attribute 'replace'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[26], line 3\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mast\u001b[39;00m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;66;03m# 문자열을 리스트로 변환\u001b[39;00m\n\u001b[1;32m----> 3\u001b[0m df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124membedding_책소개\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[43mdf\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43membedding_책소개\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mapply\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43;01mlambda\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mx\u001b[49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mlist\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mmap\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mfloat\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mx\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mreplace\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m:\u001b[49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m]\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msplit\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python311\\site-packages\\pandas\\core\\series.py:4924\u001b[0m, in \u001b[0;36mSeries.apply\u001b[1;34m(self, func, convert_dtype, args, by_row, **kwargs)\u001b[0m\n\u001b[0;32m   4789\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mapply\u001b[39m(\n\u001b[0;32m   4790\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m   4791\u001b[0m     func: AggFuncType,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   4796\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs,\n\u001b[0;32m   4797\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m DataFrame \u001b[38;5;241m|\u001b[39m Series:\n\u001b[0;32m   4798\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m   4799\u001b[0m \u001b[38;5;124;03m    Invoke function on values of Series.\u001b[39;00m\n\u001b[0;32m   4800\u001b[0m \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   4915\u001b[0m \u001b[38;5;124;03m    dtype: float64\u001b[39;00m\n\u001b[0;32m   4916\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m   4917\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mSeriesApply\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   4918\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m   4919\u001b[0m \u001b[43m        \u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   4920\u001b[0m \u001b[43m        \u001b[49m\u001b[43mconvert_dtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mconvert_dtype\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   4921\u001b[0m \u001b[43m        \u001b[49m\u001b[43mby_row\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mby_row\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   4922\u001b[0m \u001b[43m        \u001b[49m\u001b[43margs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   4923\u001b[0m \u001b[43m        \u001b[49m\u001b[43mkwargs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m-> 4924\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mapply\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python311\\site-packages\\pandas\\core\\apply.py:1427\u001b[0m, in \u001b[0;36mSeriesApply.apply\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1424\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mapply_compat()\n\u001b[0;32m   1426\u001b[0m \u001b[38;5;66;03m# self.func is Callable\u001b[39;00m\n\u001b[1;32m-> 1427\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mapply_standard\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python311\\site-packages\\pandas\\core\\apply.py:1507\u001b[0m, in \u001b[0;36mSeriesApply.apply_standard\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1501\u001b[0m \u001b[38;5;66;03m# row-wise access\u001b[39;00m\n\u001b[0;32m   1502\u001b[0m \u001b[38;5;66;03m# apply doesn't have a `na_action` keyword and for backward compat reasons\u001b[39;00m\n\u001b[0;32m   1503\u001b[0m \u001b[38;5;66;03m# we need to give `na_action=\"ignore\"` for categorical data.\u001b[39;00m\n\u001b[0;32m   1504\u001b[0m \u001b[38;5;66;03m# TODO: remove the `na_action=\"ignore\"` when that default has been changed in\u001b[39;00m\n\u001b[0;32m   1505\u001b[0m \u001b[38;5;66;03m#  Categorical (GH51645).\u001b[39;00m\n\u001b[0;32m   1506\u001b[0m action \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mignore\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(obj\u001b[38;5;241m.\u001b[39mdtype, CategoricalDtype) \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m-> 1507\u001b[0m mapped \u001b[38;5;241m=\u001b[39m \u001b[43mobj\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_map_values\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1508\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmapper\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcurried\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mna_action\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43maction\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconvert\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconvert_dtype\u001b[49m\n\u001b[0;32m   1509\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1511\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(mapped) \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(mapped[\u001b[38;5;241m0\u001b[39m], ABCSeries):\n\u001b[0;32m   1512\u001b[0m     \u001b[38;5;66;03m# GH#43986 Need to do list(mapped) in order to get treated as nested\u001b[39;00m\n\u001b[0;32m   1513\u001b[0m     \u001b[38;5;66;03m#  See also GH#25959 regarding EA support\u001b[39;00m\n\u001b[0;32m   1514\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m obj\u001b[38;5;241m.\u001b[39m_constructor_expanddim(\u001b[38;5;28mlist\u001b[39m(mapped), index\u001b[38;5;241m=\u001b[39mobj\u001b[38;5;241m.\u001b[39mindex)\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python311\\site-packages\\pandas\\core\\base.py:921\u001b[0m, in \u001b[0;36mIndexOpsMixin._map_values\u001b[1;34m(self, mapper, na_action, convert)\u001b[0m\n\u001b[0;32m    918\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(arr, ExtensionArray):\n\u001b[0;32m    919\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m arr\u001b[38;5;241m.\u001b[39mmap(mapper, na_action\u001b[38;5;241m=\u001b[39mna_action)\n\u001b[1;32m--> 921\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43malgorithms\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmap_array\u001b[49m\u001b[43m(\u001b[49m\u001b[43marr\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmapper\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mna_action\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mna_action\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconvert\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mconvert\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python311\\site-packages\\pandas\\core\\algorithms.py:1743\u001b[0m, in \u001b[0;36mmap_array\u001b[1;34m(arr, mapper, na_action, convert)\u001b[0m\n\u001b[0;32m   1741\u001b[0m values \u001b[38;5;241m=\u001b[39m arr\u001b[38;5;241m.\u001b[39mastype(\u001b[38;5;28mobject\u001b[39m, copy\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[0;32m   1742\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m na_action \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m-> 1743\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mlib\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmap_infer\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvalues\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmapper\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconvert\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mconvert\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1744\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m   1745\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m lib\u001b[38;5;241m.\u001b[39mmap_infer_mask(\n\u001b[0;32m   1746\u001b[0m         values, mapper, mask\u001b[38;5;241m=\u001b[39misna(values)\u001b[38;5;241m.\u001b[39mview(np\u001b[38;5;241m.\u001b[39muint8), convert\u001b[38;5;241m=\u001b[39mconvert\n\u001b[0;32m   1747\u001b[0m     )\n",
      "File \u001b[1;32mlib.pyx:2972\u001b[0m, in \u001b[0;36mpandas._libs.lib.map_infer\u001b[1;34m()\u001b[0m\n",
      "Cell \u001b[1;32mIn[26], line 3\u001b[0m, in \u001b[0;36m<lambda>\u001b[1;34m(x)\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mast\u001b[39;00m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;66;03m# 문자열을 리스트로 변환\u001b[39;00m\n\u001b[1;32m----> 3\u001b[0m df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124membedding_책소개\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124membedding_책소개\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mapply(\u001b[38;5;28;01mlambda\u001b[39;00m x: \u001b[38;5;28mlist\u001b[39m(\u001b[38;5;28mmap\u001b[39m(\u001b[38;5;28mfloat\u001b[39m, \u001b[43mx\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mreplace\u001b[49m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m'\u001b[39m)[\u001b[38;5;241m1\u001b[39m:\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m]\u001b[38;5;241m.\u001b[39msplit())))\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'list' object has no attribute 'replace'"
     ]
    }
   ],
   "source": [
    "import ast\n",
    "# 문자열을 리스트로 변환\n",
    "df['embedding_책소개'] = df['embedding_책소개'].apply(lambda x: list(map(float, x.replace('\\n', '')[1:-1].split())))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "다음 책들은 DB에 없습니다: 도쿄 트렌드 이트 2025, 바보멍청이똥개\n",
      "                              title  \\\n",
      "11688                        골든 크로스   \n",
      "24094      2015 현대경제연구원 휴가철 선정도서 세트   \n",
      "3780                 비열한 시장과 도마뱀의 뇌   \n",
      "5830   100대 기업 ESG 담당자가 가장 자주 하는 질문   \n",
      "4604            장하준의 경제학 명강의 시리즈 세트   \n",
      "9555              미래의 부 + 미국주식 처음공부   \n",
      "8741              책임지는 경영자 정의로운 투자자   \n",
      "40556              월급쟁이 부자들 + 똑똑한 돈   \n",
      "37463        후즈유어시티 WHO'S YOUR CITY   \n",
      "9543                    미래의 부 + 에이트   \n",
      "\n",
      "                                               full_name       cos  \n",
      "11688                  골든 크로스 주식과 부동산의 위기를 기회로 만드는 투자 전략  0.916235  \n",
      "24094                2015 현대경제연구원 휴가철 선정도서 세트   [ 전11권 ]  0.915509  \n",
      "3780     비열한 시장과 도마뱀의 뇌 경제학과 뇌과학이 밝혀낸 초수익을 내는 비상식적 투자 법칙  0.913046  \n",
      "5830                        100대 기업 ESG 담당자가 가장 자주 하는 질문  0.912847  \n",
      "4604   장하준의 경제학 명강의 시리즈 세트 나쁜 사마리아인들 + 그들이 말하지 않는 23가...  0.911815  \n",
      "9555                                   미래의 부 + 미국주식 처음공부  0.908858  \n",
      "8741                   책임지는 경영자 정의로운 투자자 ESG로 다시 쓰는 자본주의  0.907897  \n",
      "40556                   월급쟁이 부자들 + 똑똑한 돈   [ 특별구성, 전2권 ]  0.907607  \n",
      "37463        후즈유어시티 WHO'S YOUR CITY 세계의 경제 엘리트들은 어디서 사는가  0.907576  \n",
      "9543                                         미래의 부 + 에이트  0.906968  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\nunic\\AppData\\Local\\Temp\\ipykernel_19416\\405610143.py:45: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  recommended_books['cos'] = recommended_books.index.map(lambda x: similarity_scores[x])\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "# 사용자 입력받기\n",
    "user_books = ['바보멍청이똥개', '트렌드 코리아 2025', '회계 천재가 된 홍대리', '모두의 금리', '돈 공부를 시작하고 인생의 불안이 사라졌다', \n",
    "              '도쿄 트렌드 이트 2025', '레버리지', '부의 시나리오', '로지컬 씽킹', '피터 드러커 자기경영노트', '60년대생이 온다', '자본주의']\n",
    "M = 10  # 추천할 책 개수\n",
    "\n",
    "# 1. DB에서 일치하는 책 찾기 (제목 컬럼 사용)\n",
    "matched_books = df[df['title'].isin(user_books)]\n",
    "\n",
    "# 2. 존재하지 않는 책 찾기\n",
    "missing_books = set(user_books) - set(matched_books['title'])\n",
    "\n",
    "if missing_books:\n",
    "    print(f\"다음 책들은 DB에 없습니다: {', '.join(missing_books)}\")\n",
    "\n",
    "# 존재하는 책이 있는 경우에만 추천 로직 진행\n",
    "if not matched_books.empty:\n",
    "    # 3. 입력한 책들의 책소개 임베딩 가져오기\n",
    "    matched_embeddings = np.array([\n",
    "        df['embedding_책소개'].iloc[i]\n",
    "        for i in matched_books.index\n",
    "    ])\n",
    "\n",
    "    # 4. 모든 책의 책소개 임베딩 결합\n",
    "    all_embeddings = np.array([\n",
    "        df['embedding_책소개'].iloc[i]\n",
    "        for i in range(len(df))\n",
    "    ])\n",
    "\n",
    "    # 5. 사용자 책 임베딩 평균\n",
    "    user_embedding = np.mean(matched_embeddings, axis=0).reshape(1, -1)\n",
    "\n",
    "    # 6. 코사인 유사도 계산\n",
    "    similarity_scores = cosine_similarity(user_embedding, all_embeddings).flatten()\n",
    "\n",
    "    # 7. 가장 유사한 M권의 책 추천 (단, 입력한 책과 일치하는 책은 제외)\n",
    "    recommended_books_indices = np.argsort(similarity_scores)[-M-1:-1]  # 가장 유사한 M권 인덱스\n",
    "    recommended_books_indices = [idx for idx in recommended_books_indices if idx not in matched_books.index]  # 입력한 책 제외\n",
    "\n",
    "    # 8. 추천 책 가져오기\n",
    "    recommended_books = df.iloc[recommended_books_indices]\n",
    "    recommended_books['cos'] = recommended_books.index.map(lambda x: similarity_scores[x])\n",
    "    recommended_books = recommended_books[['title', 'full_name', 'cos']].sort_values(by='cos', ascending=False)\n",
    "\n",
    "    # 추천 책 출력\n",
    "    print(recommended_books)\n",
    "else:\n",
    "    print(\"입력된 책 중 일치하는 책이 없습니다.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                              title  \\\n",
      "24094      2015 현대경제연구원 휴가철 선정도서 세트   \n",
      "11688                        골든 크로스   \n",
      "5830   100대 기업 ESG 담당자가 가장 자주 하는 질문   \n",
      "17110                 그린란드상어처럼 생존하라   \n",
      "51856        내 인생의 후반전은 아직 결정되지 않았다   \n",
      "12531                         부의 재편   \n",
      "4604            장하준의 경제학 명강의 시리즈 세트   \n",
      "37463        후즈유어시티 WHO'S YOUR CITY   \n",
      "20948          퍼스트 무버 4차 산업혁명의 선도자들   \n",
      "1258                       피크아웃 코리아   \n",
      "\n",
      "                                               full_name       cos  \n",
      "24094                2015 현대경제연구원 휴가철 선정도서 세트   [ 전11권 ]  0.923334  \n",
      "11688                  골든 크로스 주식과 부동산의 위기를 기회로 만드는 투자 전략  0.920871  \n",
      "5830                        100대 기업 ESG 담당자가 가장 자주 하는 질문  0.918648  \n",
      "17110          그린란드상어처럼 생존하라 부분에선 실패해도 전체에선 이기는 기업의 생존기술  0.916318  \n",
      "51856                             내 인생의 후반전은 아직 결정되지 않았다  0.916292  \n",
      "12531                      부의 재편 새로운 부와 마켓, 그리고 전혀 다른 기회  0.916143  \n",
      "4604   장하준의 경제학 명강의 시리즈 세트 나쁜 사마리아인들 + 그들이 말하지 않는 23가...  0.916015  \n",
      "37463        후즈유어시티 WHO'S YOUR CITY 세계의 경제 엘리트들은 어디서 사는가  0.915794  \n",
      "20948                               퍼스트 무버 4차 산업혁명의 선도자들  0.915412  \n",
      "1258                           피크아웃 코리아 미래가 없는 사회에서 살아남기  0.915330  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\nunic\\AppData\\Local\\Temp\\ipykernel_19416\\1949704286.py:62: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  recommended_books['cos'] = recommended_books.index.map(lambda x: similarity_scores[x])\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from konlpy.tag import Okt  # Okt 형태소 분석기 불러오기\n",
    "from gensim.models import FastText\n",
    "\n",
    "\n",
    "# FastText 모델 불러오기 (모델 경로에 맞게 수정 필요)\n",
    "fasttext_model = FastText.load('C:/Users/nunic/Desktop/workspace/gamnyam_package/study/project_PJT/3_책쳌/web/streamlit_/fasttext_model.bin')\n",
    "\n",
    "# Okt 형태소 분석기 불러오기\n",
    "okt = Okt()\n",
    "\n",
    "# 사용자 입력받기\n",
    "user_books = ['트렌드 코리아 2025', '회계 천재가 된 홍대리', '모두의 금리', '돈 공부를 시작하고 인생의 불안이 사라졌다', \n",
    "              '도쿄 트렌드 인사이트 2025', '레버리지', '부의 시나리오', '로지컬 씽킹', '피터 드러커 자기경영노트', '60년대생이 온다', '자본주의']\n",
    "M = 10  # 추천할 책 개수\n",
    "\n",
    "# 1. DB에서 일치하는 책 찾기 (제목 컬럼 사용)\n",
    "matched_books = df[df['title'].isin(user_books)]\n",
    "\n",
    "# 2. 존재하지 않는 책 찾기\n",
    "missing_books = set(user_books) - set(matched_books['title'])\n",
    "\n",
    "if missing_books:\n",
    "    print(f\"다음 책들은 DB에 없습니다: {', '.join(missing_books)}\")\n",
    "\n",
    "# 존재하는 책들의 임베딩 가져오기\n",
    "matched_embeddings = np.array([\n",
    "    df['embedding_책소개'].iloc[i]\n",
    "    for i in matched_books.index\n",
    "])\n",
    "\n",
    "# 3. 존재하지 않는 책의 제목을 Okt로 토큰화하고 임베딩 계산\n",
    "missing_embeddings = []\n",
    "if missing_books:\n",
    "    for book in missing_books:\n",
    "        tokens = okt.morphs(book)  # Okt를 이용한 토큰화\n",
    "        embedding = np.mean([fasttext_model.wv[token] for token in tokens if token in fasttext_model.wv], axis=0)  # FastText 임베딩 계산\n",
    "        missing_embeddings.append(embedding)\n",
    "\n",
    "# 4. 존재하는 책의 임베딩과 없는 책의 임베딩을 합쳐서 평균 계산\n",
    "if matched_embeddings.size > 0 or missing_embeddings:\n",
    "    total_embeddings = np.vstack([matched_embeddings] + missing_embeddings)  # 임베딩 결합\n",
    "    user_embedding = np.mean(total_embeddings, axis=0).reshape(1, -1)  # 임베딩 평균 계산\n",
    "\n",
    "    # 5. 모든 책의 책소개 임베딩 결합\n",
    "    all_embeddings = np.array([\n",
    "        df['embedding_책소개'].iloc[i]\n",
    "        for i in range(len(df))\n",
    "    ])\n",
    "\n",
    "    # 6. 코사인 유사도 계산\n",
    "    similarity_scores = cosine_similarity(user_embedding, all_embeddings).flatten()\n",
    "\n",
    "    # 7. 가장 유사한 M권의 책 추천 (단, 입력한 책과 일치하는 책은 제외)\n",
    "    recommended_books_indices = np.argsort(similarity_scores)[-M-1:-1]  # 가장 유사한 M권 인덱스\n",
    "    recommended_books_indices = [idx for idx in recommended_books_indices if idx not in matched_books.index]  # 입력한 책 제외\n",
    "\n",
    "    # 8. 추천 책 가져오기\n",
    "    recommended_books = df.iloc[recommended_books_indices]\n",
    "    recommended_books['cos'] = recommended_books.index.map(lambda x: similarity_scores[x])\n",
    "    recommended_books = recommended_books[['title', 'full_name', 'cos']].sort_values(by='cos', ascending=False)\n",
    "\n",
    "    # 추천 책 출력\n",
    "    print(recommended_books)\n",
    "else:\n",
    "    print(\"입력된 책 중 일치하는 책이 없습니다.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "nlp",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
